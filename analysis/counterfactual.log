
  ___  ____  ____  ____  ____ (R)
 /__    /   ____/   /   ____/
___/   /   /___/   /   /___/   15.1   Copyright 1985-2017 StataCorp LLC
  Statistics/Data Analysis            StataCorp
                                      4905 Lakeway Drive
     MP - Parallel Edition            College Station, Texas 77845 USA
                                      800-STATA-PC        http://www.stata.com
                                      979-696-4600        stata@stata.com
                                      979-696-4601 (fax)

Single-user 2-core Stata perpetual license:
       Serial number:  501506203290
         Licensed to:  Miklos Koren
                       CEU MicroData


Notes:
      1.  Stata is running in batch mode.
      2.  Unicode is supported; see help unicode_advice.
      3.  More than 2 billion observations are allowed; see help obs_advice.
      4.  Maximum number of variables is set to 5000; see help set_maxvar.

. do counterfactual.do 

. clear all

. 
. import delimited "../data/derived/crosswalk/industry.csv", varnames(1) clear 
> case(preserve)
(3 vars, 90 obs)

. merge 1:1 industry_code using "../data/clean/industry-employment/industry-emp
> loyment.dta", nogen keep(master match)

    Result                           # of obs.
    -----------------------------------------
    not matched                             2
        from master                         2  
        from using                          0  

    matched                                88  
    -----------------------------------------

. rename employment ces_employment

. tempfile industry

. save `industry', replace
(note: file /var/folders/w1/7d52g2y563517gpc7n0sv5_r0000gn/T//St48919.000001 no
> t found)
file /var/folders/w1/7d52g2y563517gpc7n0sv5_r0000gn/T//St48919.000001 saved

. 
. import delimited "../data/derived/crosswalk/2digit_names.csv", varnames(1) cl
> ear case(preserve)
(2 vars, 20 obs)

. tempfile digit2

. save `digit2', replace
(note: file /var/folders/w1/7d52g2y563517gpc7n0sv5_r0000gn/T//St48919.000002 no
> t found)
file /var/folders/w1/7d52g2y563517gpc7n0sv5_r0000gn/T//St48919.000002 saved

. 
. do "industry_location_panel.do"

. import delimited "../data/derived/occupation/naics_risk.csv", varnames(1) cle
> ar
(6 vars, 84 obs)

. tempfile occupation

. save `occupation', replace
(note: file /var/folders/w1/7d52g2y563517gpc7n0sv5_r0000gn/T//St48919.000003 no
> t found)
file /var/folders/w1/7d52g2y563517gpc7n0sv5_r0000gn/T//St48919.000003 saved

. 
. use "../data/clean/cbp/zip_code_business_patterns.dta", clear

. merge m:1 industry_code using `occupation', keep(match) nogen

    Result                           # of obs.
    -----------------------------------------
    not matched                             0
    matched                           464,804  
    -----------------------------------------

. 
end of do-file

. merge m:1 industry_code using `industry', nogen keep(master match) keepusing(
> industry_label ces_employment growth)

    Result                           # of obs.
    -----------------------------------------
    not matched                             0
    matched                           464,804  
    -----------------------------------------

. 
. * drop hospitals and clinics
. drop if inlist(industry_code, 621, 622)
(15,186 observations deleted)

. 
. * regional employment weight from CBP, sectoral weight from CES
. tempvar sum

. egen `sum' = sum(cond(!missing(population_density,communication_share),employ
> ment,0)), by(industry_code)

. generate employment_weight = cond(!missing(population_density,communication_s
> hare),employment,0)/`sum'*ces_employment
(1,209 missing values generated)

. 
. /* 
> Calibrate epsilon to gamma=1.04 in
> 
> Ciccone, Antonio, and Robert Hall. 1996. “Productivity and the Density of Eco
> nomic Activity.” 
> The American Economic Review 86 (1): 54–70.
> 
> page 62.
> 
> density^agglomeration = density^(epsilon * chi)
> */
. scalar agglomeration = 0.04

. generate LHS = agglomeration * ln(population_density)
(5,984 missing values generated)

. generate RHS = (communication_share/100) * ln(population_density)
(5,984 missing values generated)

. 
. regress LHS RHS [aw=employment_weight]
(sum of wgt is 97,228.1424131829)

      Source |       SS           df       MS      Number of obs   =   442,430
-------------+----------------------------------   F(1, 442428)    =  84705.43
       Model |  310.454682         1  310.454682   Prob > F        =    0.0000
    Residual |  1621.54712   442,428   .00366511   R-squared       =    0.1607
-------------+----------------------------------   Adj R-squared   =    0.1607
       Total |  1932.00181   442,429  .004366806   Root MSE        =    .06054

------------------------------------------------------------------------------
         LHS |      Coef.   Std. Err.      t    P>|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         RHS |    .019571   .0000672   291.04   0.000     .0194392    .0197028
       _cons |     .21392   .0001674  1278.22   0.000      .213592     .214248
------------------------------------------------------------------------------

. scalar epsilon = _b[RHS]

. generate chi = communication_share/100

. generate gamma = chi/(1-chi)

. 
. * Eq 4
. generate contact = population_density^(epsilon*(1-chi))
(5,527 missing values generated)

. 
. * current number of contacts
. summarize contact [aw=employment_weight]

    Variable |     Obs      Weight        Mean   Std. Dev.       Min        Max
-------------+-----------------------------------------------------------------
     contact | 442,887  97392.5001    1.086139   .0568988          0   1.217032

. scalar current_contact = r(mean)

. 
. * target contact is half
. scalar target_contact = current_contact * 0.5

. 
. * loop to find the cap
. scalar cap = 10000

. scalar average = current_contact 

. generate counterfactual = .
(449,618 missing values generated)

. while average > target_contact {
  2.         quietly replace counterfactual = min(contact, min(population_densi
> ty, cap)^(epsilon*(1-chi)))
  3.         quietly summarize counterfactual [aw=employment_weight]
  4.         scalar average = r(mean)
  5.         scalar cap = 0.90*cap
  6. }

. 
. generate contact_ratio = counterfactual / contact
(5,984 missing values generated)

. * Eq 6 from the paper
. generate labor_subsidy = 100 - 100 * (1 - chi*contact_ratio) * (contact_ratio
> )^gamma / (1-chi)
(5,984 missing values generated)

. summarize labor_subsidy [aw=employment_weight]

    Variable |     Obs      Weight        Mean   Std. Dev.       Min        Max
-------------+-----------------------------------------------------------------
labor_subs~y | 442,430  97228.1424    11.35373   5.787354   2.144916   29.86782

. 
. * compute for nyc
. merge m:1 zip using "nyc_zip.dta", keep(master match)

    Result                           # of obs.
    -----------------------------------------
    not matched                       443,603
        from master                   443,603  (_merge==1)
        from using                          0  (_merge==2)

    matched                             6,015  (_merge==3)
    -----------------------------------------

. generate nyc = (_m==3)

. summarize population_density if nyc==1 [aw=employment_weight]

    Variable |     Obs      Weight        Mean   Std. Dev.       Min        Max
-------------+-----------------------------------------------------------------
population~y |   6,014  3287.95922    19149.36   12127.81          0   57231.17

. summarize labor_subsidy if nyc==1 [aw=employment_weight]

    Variable |     Obs      Weight        Mean   Std. Dev.       Min        Max
-------------+-----------------------------------------------------------------
labor_subs~y |   5,844  3220.69291    12.40142   5.390354   2.817928   29.86782

. 
. save "wage_subsidy.dta", replace
file wage_subsidy.dta saved

. do "employment-growth.do"

. preserve

.         generate wage_subsidy = employment_weight * labor_subsidy
(7,188 missing values generated)

.         collapse (firstnm) ces_employment growth affected_share (sum) wage_su
> bsidy employment_weight, by(industry_code industry_label)

.         replace wage_subsidy =  wage_subsidy / employment_weight
(81 real changes made, 2 to missing)

.         
.         generate str label = ""
(81 missing values generated)

.         replace label = industry_label if inlist(industry_code, 487, 722, 442
> , 448, 452, 519, 486, 113, 451, 721, 446)
variable label was str1 now str45
(11 real changes made)

.         
.         tw ///
>         (lfitci growth wage_subsidy   ) ///
>         (scatter growth wage_subsidy,  msymbol(circle_hollow) mlabel(label)),
>  ///
>         scheme(s2mono) graphregion(color(white)) ///
>         ytitle("Change in employment between Feb and Apr (%)" ) ///
>         xtitle("Wage subsidy to compensate drop in contacts (percent)") ///
>         legend(region(lstyle(none)) order(2 "Regression line" 1 "Confidence i
> nterval")) ///
>         graphregion(margin(1 40 1 1)) aspect(1)

.         
.         graph export "../text/fig5.eps", replace
(file ../text/fig5.eps written in EPS format)

.         graph export "../text/fig5.pdf", replace
(file ../text/fig5.pdf written in PDF format)

. 
.         tw ///
>         (scatter growth affected_share,  msymbol(circle_hollow) mlabel(label)
> ), ///
>         scheme(s2mono) graphregion(color(white)) ///
>         ytitle("Change in employment between Feb and Apr (%)" ) ///
>         xtitle("Share of workers in affected occupations (%)") ///
>         legend(off) ///
>         graphregion(margin(1 40 1 1)) aspect(1)

.         
.         graph export "../text/fig5b.pdf", replace
(file ../text/fig5b.pdf written in PDF format)

.         
. restore 

. 
end of do-file

. 
. do "aggregate2digit.do"

. generate naics_2d = int(industry_code/10)

. replace naics_2d = 31 if (naics_2d>=31) & (naics<=33)
(25,843 real changes made)

. replace naics_2d = 44 if (naics_2d>=44) & (naics<=45)
(30,239 real changes made)

. replace naics_2d = 48 if (naics_2d>=48) & (naics<=49)
(3,411 real changes made)

. 
end of do-file

. * weighted cost ratio
. replace labor_subsidy = labor_subsidy * employment_weight
(443,634 real changes made, 1,204 to missing)

. 
. collapse (sum) labor_subsidy employment_weight, by(naics_2d)

. * merge on names
. merge 1:1 naics_2d using `digit2', nogen keep(master match)

    Result                           # of obs.
    -----------------------------------------
    not matched                             0
    matched                                19  
    -----------------------------------------

. 
. replace labor_subsidy = round(labor_subsidy/employment_weight, 0.1)
(19 real changes made)

. rename employment_weight employment

. replace employment = round(employment)
(19 real changes made)

. 
. * calculate weighted average
. summarize labor_subsidy [fw=employment], meanonly

. scalar average = r(mean)

. scalar N = r(N)

. 
. gsort -labor_subsidy

. 
. * add a row for average
. set obs 20
number of observations (_N) was 19, now 20

. replace industry_label = "Average" in 20
(1 real change made)

. replace labor_subsidy = average in 20
(1 real change made)

. replace employment = N in 20
(1 real change made)

. 
. order industry_label labor_subsidy employment

. export delimited "cost_by_naics2.csv", replace
file cost_by_naics2.csv saved

. 
end of do-file
